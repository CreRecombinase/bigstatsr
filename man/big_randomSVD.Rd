% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/randomSVD.R
\name{big_randomSVD}
\alias{big_randomSVD}
\title{Partial SVD}
\usage{
big_randomSVD(X, fun.scaling, ind.train = seq(nrow(X)), block.size = 1000,
  K = 10, I = 20, use.Eigen = !detect_MRO(), ncores = 1,
  backingpath = NULL)
}
\arguments{
\item{X}{A \link[bigmemory:big.matrix-class]{big.matrix}.
You shouldn't have missing values in your data.}

\item{fun.scaling}{A function that returns a named list of mean and
sd for every column, to scale each of their elements such as followed:
\deqn{\frac{X_{i,j} - mean_j}{sd_j}}.}

\item{ind.train}{An optional vector of the row indices that are used,
for the training part. If not specified, all data are used.}

\item{block.size}{Maximum number of columns read at once.
Default is \code{1000}.}

\item{K}{Number of PCs to compute. This algorithm shouldn't
be used to compute a lot of PCs. Default is \code{10}.}

\item{I}{The number of iterations of the algorithm. Default is \code{20}.}

\item{use.Eigen}{Should the \code{Eigen} library be used
for matrix computations? Default tries to detect MRO. See details.}

\item{ncores}{Number or cores used. Default doesn't use parallelism.}

\item{backingpath}{If \code{X} is filebacked and parallelism is used,
the path where are stored the files that are backing \code{X}.}
}
\description{
A randomized algorithm for SVD (or PCA) of a "big.matrix".
}
\details{
For matrix computations, using \code{Eigen} library is faster.
However, if you link \code{R} with an optimized math library,
using \code{R}'s base operations is even much faster.

For example, you can easily link \code{R} with the
\href{https://software.intel.com/en-us/intel-mkl}{Intel®
Math Kernel Library} (Intel® MKL) through
\href{https://mran.revolutionanalytics.com/open/}{Microsoft
R Open} (MRO). It really improves performance
of \code{R} and \code{RcppArmadillo} matrix computations,
yet not the ones of \code{RcppEigen} (at least not directly).

So, \enumerate{
\item \code{Eigen} should be prefered if you don't change anything,
\item base \code{R} should be prefered if you use MRO,
\item \code{Eigen} may be prefered if you manage to link \code{RcppEigen}
with the MKL (please \href{mailto:florian.prive.21@gmail.com}{contact me}
if you do!).}
}
\examples{
# Simulating some data
X <- big.matrix(1023, 511)
X[] <- rnorm(length(X))


# Comparing with prcomp
test <- big_randomSVD(X = X,
                      fun.scaling = big_scale(),
                      block.size = 50,
                      ncores = 1)
str(test)

pca <- prcomp(X[,], center = TRUE, scale. = TRUE)

# same scaling
print(all.equal(test$means, pca$center))
print(all.equal(test$sds, pca$scale))

# scores and loadings are the same or opposite
scores <- test$u \%*\% diag(test$d)
plot(as.numeric(scores), as.numeric(pca$x[, 1:10]))
plot(as.numeric(test$v), as.numeric(pca$rotation[, 1:10]))


# Using only half of the data for "training"
ind <- sort(sample(nrow(X), nrow(X)/2))

test2 <- big_randomSVD(X = X, ind.train = ind,
                       fun.scaling = big_scale(),
                       block.size = 10, ncores = 1)

pca2 <- prcomp(X[ind, ], center = TRUE, scale. = TRUE)

# same scaling
print(all.equal(test2$means, pca2$center))
print(all.equal(test2$sds, pca2$scale))

# scores and loadings are the same or opposite
scores2 <- test2$u \%*\% diag(test2$d)
plot(as.numeric(scores2), as.numeric(pca2$x[, 1:10]))
plot(as.numeric(test2$v), as.numeric(pca2$rotation[, 1:10]))
}
\references{
The "blanczos" algorithm in
Rokhlin, V., Szlam, A., & Tygert, M. (2010).
A Randomized Algorithm for Principal Component Analysis.
SIAM Journal on Matrix Analysis and Applications, 31(3), 1100–1124.
doi:10.1137/080736417
}
\seealso{
\link{big_scale} \link[stats:prcomp]{prcomp} \link{svd}
}

