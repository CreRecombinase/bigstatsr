% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/crossprodSelf.R
\name{big_crossprodSelf}
\alias{big_crossprodSelf}
\title{Crossprod for a big.matrix.}
\usage{
big_crossprodSelf(X, fun.scaling, ind.train = seq(nrow(X)),
  block.size = 1000, use.Eigen = TRUE, ...)
}
\arguments{
\item{X}{A \link[bigmemory:big.matrix-class]{big.matrix}.
You shouldn't have missing values in your data.}

\item{fun.scaling}{A function that returns a named list of mean and
sd for every column, to scale each of their elements such as followed:
\eqn{\frac{X_{i,j} - mean_j}{sd_j}}.}

\item{ind.train}{An optional vector of the row indices that are used,
for the training part. If not specified, all data are used.}

\item{block.size}{Maximum number of columns read at once.
Default is \code{1000}.}

\item{use.Eigen}{Should the \code{Eigen} library be used
for matrix computations? Default is \code{TRUE}. See details.}

\item{...}{Arguments passed on to \code{bigmemory::big.matrix}
\describe{
  \item{dimnames}{a list of the row and column names; use with caution 
for large objects.}
  \item{separated}{use separated column organization of the data; 
see details.}
  \item{backingfile}{the root name for the file(s) for the cache of \code{x}.}
  \item{backingpath}{the path to the directory containing the file 
backing cache.}
  \item{descriptorfile}{the name of the file to hold the backingfile 
description, for subsequent use with \code{\link{attach.big.matrix}}; 
if \code{NULL}, the \code{backingfile} is used as the root part of the 
descriptor file name.  The descriptor file is placed in the same directory 
as the backing files.}
  \item{binarydescriptor}{the flag to specify if the binary RDS format 
should be used for the backingfile description, for subsequent use with 
\code{\link{attach.big.matrix}}; if \code{NULL} of \code{FALSE}, the 
\code{dput()} file format is used.}
  \item{shared}{\code{TRUE} by default, and always \code{TRUE} if the 
\code{big.matrix} is file-backed.  For a non-filebacked \code{big.matrix}, 
\code{shared=FALSE} uses non-shared memory, which can be more stable for 
large (say, >50\% of RAM) objects.  Shared memory allocation can sometimes 
fail in such cases due to exhausted shared-memory resources in the system.}
}}
}
\value{
\eqn{X.train^T X.train} as a \code{big.matrix}. Its dimension
is ncol(X) x ncol(X) and its type is \code{double}.
}
\description{
Compute \eqn{X.train^T X.train} for a \code{big.matrix} X
after applying a particular scaling to it.
}
\details{
For matrix computations, using \code{Eigen} library is faster.
However, if you link \code{R} with an optimized math library,
using \code{R}'s base operations is even much faster.

For example, you can easily link \code{R} with the
\href{https://software.intel.com/en-us/intel-mkl}{Intel®
Math Kernel Library} (Intel® MKL) through
\href{https://mran.revolutionanalytics.com/open/}{Microsoft
R Open} (MRO). It really improves performance
of \code{R} and \code{RcppArmadillo} matrix computations,
yet not the ones of \code{RcppEigen} (at least not directly).

So, \enumerate{
\item \code{Eigen} should be prefered if you don't change anything,
\item base \code{R} should be prefered if you use MRO,
\item \code{Eigen} may be prefered if you manage to link \code{RcppEigen}
with the MKL (please \href{mailto:florian.prive.21@gmail.com}{contact me}
if you do!).}
}
\examples{
# Simulating some data
X <- big.matrix(17, 41)
X[] <- rnorm(length(X))

# Comparing with tcrossprod
test <- big_crossprodSelf(X, fun.scaling = big_noscale)
print(all.equal(test[,], crossprod(X[,])))

# Using only half of the data for "training"
ind <- sort(sample(nrow(X), nrow(X)/2))
test <- big_crossprodSelf(X, fun.scaling = big_noscale,
                          ind.train = ind)
print(all.equal(test[,], crossprod(X[ind, ])))
}

