% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/apply-parallelize.R
\name{big_apply}
\alias{big_apply}
\title{Split-Apply-Combine}
\usage{
big_apply(X., a.FUN, a.combine, ncores = 1, block.size = 1000,
  ind = cols_along(X.), ...)
}
\arguments{
\item{X.}{Either a \link[=big.matrix-class]{big.matrix} or
a \link[=big.matrix.descriptor-class]{big.matrix.descriptor}.}

\item{a.FUN}{The function to be applied to each subset matrix.
It must take a \code{big.matrix} as first argument and \code{ind}, a vector of
indices, which are used to split the data. Example: if you want to apply
a function to \code{X[ind.row, ind.col]}, you may use
\code{X[ind.row, ind.col[ind]]} in \code{a.FUN}.}

\item{a.combine}{function that is used by \link{foreach} to process the tasks
results as they generated. This can be specified as either a function or a
non-empty character string naming the function. Specifying 'c' is useful
for concatenating the results into a vector, for example. The values 'cbind'
and 'rbind' can combine vectors into a matrix. The values '+' and '*' can be
used to process numeric data. By default, the results are returned in a list.}

\item{ncores}{Number of cores used. Default doesn't use parallelism.}

\item{block.size}{Maximum number of columns read at once.
Default is \code{1000}. This parameter controls the trade-off between
memory usage and speed. Basically, the more you can load at once,
the quicker will be the execution time, at the expense of memory usage.}

\item{ind}{Initial vector of subsetting indices.}

\item{...}{Extra arguments to be passed to \code{a.FUN}.}
}
\value{
The result of \link{foreach}.
}
\description{
A Split-Apply-Combine strategy to apply common R functions to a \code{big.matrix}.
}
\details{
This function splits indices in parts, then apply a given function to each
subset matrix and finally combine the results. If parallelization is used,
this function splits indices in parts for parallelization, then split again
them on each core, apply a given function to each part and finally combine
the results (on each cluster and then from each cluster).
}
\examples{
X.desc <- big_attachExtdata()

# get the means of each column
colMeans_sub <- function(X, ind) colMeans(X[, ind])
colmeans <- big_apply(X.desc, a.FUN = colMeans_sub, a.combine = 'c')

# get the norms of each column
colNorms_sub <- function(X, ind) sqrt(colSums(X[, ind]^2))
colnorms <- big_apply(X.desc, colNorms_sub, a.combine = 'c')

# get the sums of each row
# split along rows: need to change the "complete" `ind` parameter
rowsums <- big_apply(X.desc, a.FUN = function(X, ind) rowSums(X[ind, ]),
                     ind = rows_along(X.desc), a.combine = 'c',
                     block.size = 100)
# it is usually preferred to split along columns
# because `big.matrix` are stored by column.
rowsums2 <- big_apply(X.desc, a.FUN = function(X, ind) rowSums(X[, ind]),
                      a.combine = '+')

## Every extra parameter to `a.FUN` should be passed to `big_apply`
# get the crossproduct between X and a matrix A
# note that we don't explicitly pass `ind.col` to `a.FUN`
body(big_cprodMat)

# get the product between X and a matrix B
# here, we must explicitly pass `ind.col` to `a.FUN`
# because the right matrix also needs to be subsetted.
body(big_prodMat)
}
\seealso{
\link{big_parallelize}
}
