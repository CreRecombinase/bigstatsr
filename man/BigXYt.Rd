% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/BigXYt.R
\name{BigXYt}
\alias{BigXYt}
\title{Linear kernel matrices for a big.matrix.}
\usage{
BigXYt(X, block.size, ind.train = seq(nrow(X)), vec.center = rep(0,
  length(ind.train)), vec.scale = rep(1, length(ind.train)),
  use.Eigen = TRUE, progress = TRUE)
}
\arguments{
\item{X}{A big.matrix.
You shouldn't have missing values in your data.}

\item{block.size}{Maximum number of columns read at once.}

\item{ind.train}{An optional vector of the row indices that are used,
for the training part.
If not specified, all data are used.}

\item{vec.center}{Vector that will be subtracted to the matrix,
columnwise. Typically, the mean of each column.
See \code{\link{colmeans}}.}

\item{vec.scale}{Vector that will be divided to the matrix
(after the substraction), columnwise.
Typically, the sd of each column? See \code{\link{colsds}}.}

\item{use.Eigen}{Use the \code{Eigen} library to compute
\eqn{X X^T}? \code{TRUE} is the default.
If \code{FALSE}, use \code{R}'s \code{tcrossprod}. See details.}

\item{progress}{Use a progress bar for the computation
of the correlation matrix? Default is \code{TRUE}.}
}
\value{
Either \itemize{
\item A \code{big.matrix} of type \code{double} if all rows are used
in \code{ind.train}.
\item Two \code{big.matrix} of type \code{double}. One for
\eqn{X.train X.train^T} to get Principal Components
and one for \eqn{X.test X.train^T} to project the rest of the data.}
}
\description{
Compute linear kernel matrices for a "big.matrix"
after applying a particular scaling to it.
}
\details{
To compute \eqn{X X^T}, using \code{Eigen} library is faster.
However, if you link \code{R} with an optimized math library,
using \code{R}'s \code{tcrossprod} can be faster.

For example, you can easily link \code{R} with the
\href{https://software.intel.com/en-us/intel-mkl}{Intel®
Math Kernel Library} (Intel® MKL) through
\href{https://mran.revolutionanalytics.com/open/}{Microsoft
R Open} (MRO). It really improves performance
of \code{R} and \code{RcppArmadillo} matrix computations,
yet not the ones of \code{RcppEigen} (at least not directly).

So, \enumerate{
\item \code{Eigen} should be prefered if you don't change anything,
\item base \code{R} should be prefered if you use MRO,
\item \code{Eigen} may be prefered if you manage to link \code{RcppEigen}
with the MKL (please \href{mailto:florian.prive.21@gmail.com}{contact me}
if you do!).}
}
\examples{
# Simulating some data
X <- big.matrix(100, 100)
X[] <- rnorm(length(X))


# center and scale
vec.center <- colmeans(X)
vec.scale <- colsds(X)

# Comparing with tcrossprod
test <- BigXYt(X = X,
               block.size = 10,
               vec.center = vec.center,
               vec.scale = vec.scale)

mat <- sweep(sweep(X[,], 2, vec.center, '-'), 2, vec.scale, '/')
diff <- test[,] - tcrossprod(mat)
print(max(abs(diff)))


# Using only half of the data for "training"
ind <- sort(sample(nrow(X), nrow(X)/2))
vec.center <- colmeans(X, ind)
vec.scale <- colsds(X, ind)

test <- BigXYt(X = X,
               block.size = 10,
               ind.train = ind,
               vec.center = vec.center,
               vec.scale = vec.scale)

mat1 <- sweep(sweep(X[ind, ],  2, vec.center, '-'), 2, vec.scale, '/')
mat2 <- sweep(sweep(X[-ind, ], 2, vec.center, '-'), 2, vec.scale, '/')
diff1 <- test[[1]][,] - tcrossprod(mat1)
print(max(abs(diff1)))
diff2 <- test[[2]][,] - tcrossprod(mat2, mat1)
print(max(abs(diff2)))
}
\seealso{
\code{\link{tcrossprod}}
}

