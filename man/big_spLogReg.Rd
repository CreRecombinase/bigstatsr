% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/biglasso.R
\name{big_spLogReg}
\alias{big_spLogReg}
\title{Sparse logistic regression}
\usage{
big_spLogReg(X, y01.train, ind.train = rows_along(X), covar.train = NULL,
  ...)
}
\arguments{
\item{X}{A \link[=FBM-class]{FBM}.}

\item{y01.train}{Vector of responses, corresponding to \code{ind.train}.
\strong{Must be only 0s and 1s.}}

\item{ind.train}{An optional vector of the row indices that are used,
for the training part. If not specified, all rows are used.
\strong{Don't use negative indices.}}

\item{covar.train}{Matrix of covariables to be added in each model to correct
for confounders (e.g. the scores of PCA), corresponding to \code{ind.train}.
Default is \code{NULL} and corresponds to only adding an intercept to each model.}

\item{...}{Arguments passed on to \code{COPY_biglasso_part}
\describe{
  \item{}{}
}}
}
\description{
Sparse logistic regression
}
\details{
\strong{This is a modified version of one function of
\href{https://github.com/YaohuiZeng/biglasso}{package biglasso}}.
It adds the possibility to train models with covariables and use many
types of \code{FBM} (not only \code{double} ones).
Yet, it only corresponds to \code{screen = "SSR"} (Sequential Strong Rules).
}
\examples{
set.seed(1)

# simulating some data
N <- 73
M <- 430
X <- FBM(N, M, init = rnorm(N * M, sd = 5), type = "integer")
y <- sample(0:1, size = N, replace = TRUE)
covar <- matrix(rnorm(N * 3), N)

# error, only handle `double` `big.matrix` objects
X2 <- bigmemory::as.big.matrix(X[], type = "integer", shared = FALSE)
\dontrun{biglasso::biglasso(X2, y, family = "binomial")}

# OK here
test2 <- big_spLogReg(X, y)
str(test2)

# how to use covariables?
X2 <- bigmemory::as.big.matrix(cbind(X[,], covar), type = "double",
                               shared = FALSE)
test <- biglasso::biglasso(X2, y, family = "binomial", lambda.min = 0.01,
                           alpha = 0.5, penalty = "enet")
test2 <- big_spLogReg(X, y, covar.train = covar, alpha = 0.5)
# verification
all.equal(test2$lambda, test$lambda)
all.equal(test2$beta@x, test$beta[-1, ]@x)
all.equal(test2$intercept, test$beta[1, ])
}
\references{
Tibshirani, R., Bien, J., Friedman, J., Hastie, T.,
Simon, N., Taylor, J. and Tibshirani, R. J. (2012),
Strong rules for discarding predictors in lasso-type problems.
Journal of the Royal Statistical Society:
Series B (Statistical Methodology), 74: 245â€“266.
\url{http://dx.doi.org/10.1111/j.1467-9868.2011.01004.x}.

Zeng, Y., and Breheny, P. (2016). The biglasso Package: A Memory- and
Computation-Efficient Solver for Lasso Model Fitting with Big Data in R.
arXiv preprint arXiv:1701.05936. \url{https://arxiv.org/abs/1701.05936}.
}
\seealso{
\link[glmnet:glmnet]{glmnet} \link[biglasso:biglasso]{biglasso}
}
