% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/SVD.R
\name{big_SVD}
\alias{big_SVD}
\title{SVD}
\usage{
big_SVD(X, fun.scaling, ind.train = seq(nrow(X)), block.size = 1000,
  k = NULL, thr.eigval = 0.001, use.Eigen = !detect_MRO(),
  returnU = TRUE, returnV = TRUE)
}
\arguments{
\item{X}{A \link[bigmemory:big.matrix-class]{big.matrix}.
You shouldn't have missing values in your data.}

\item{fun.scaling}{A function that returns a named list of
\strong{\code{mean}} and \strong{\code{sd}} for every column, to scale each of their elements
such as followed: \deqn{\frac{X_{i,j} - mean_j}{sd_j}}.}

\item{ind.train}{An optional vector of the row indices that are used,
for the training part. If not specified, all data are used.}

\item{block.size}{Maximum number of columns read at once.
Default is \code{1000}.}

\item{k}{Number of PCs to compute. Default is all.}

\item{thr.eigval}{Threshold to remove "unsignificant" PCs.
Default is \code{1e-3}.}

\item{use.Eigen}{Should the \code{Eigen} library be used
for matrix computations? Default tries to detect MRO. See details.}

\item{returnU}{Logical whether to return U or not. Default is \code{TRUE}.}

\item{returnV}{Logical whether to return V or not. Default is \code{TRUE}.}
}
\description{
An algorithm for SVD (or PCA) of a \code{big.matrix} through the eigen
decomposition of the covariance between variables (primal)
or observations (dual).
}
\details{
For matrix computations, using \code{Eigen} library is faster.
However, if you link \code{R} with an optimized math library,
using \code{R}'s base operations is even much faster.

For example, you can easily link \code{R} with the
\href{https://software.intel.com/en-us/intel-mkl}{Intel®
Math Kernel Library} (Intel® MKL) through
\href{https://mran.revolutionanalytics.com/open/}{Microsoft
R Open} (MRO). It really improves performance
of \code{R} and \code{RcppArmadillo} matrix computations,
yet not the ones of \code{RcppEigen} (at least not directly).

So, \enumerate{
\item \code{Eigen} should be prefered if you don't change anything,
\item base \code{R} should be prefered if you use MRO,
\item \code{Eigen} may be prefered if you manage to link \code{RcppEigen}
with the MKL (please \href{mailto:florian.prive.21@gmail.com}{contact me}
if you do!).}
}
\examples{
# Simulating some data
X <- big.matrix(73, 43)
X[] <- rnorm(length(X))


# Comparing with prcomp
test <- big_SVD(X = X,
                fun.scaling = big_scale(),
                block.size = 10)
str(test)

pca <- prcomp(X[,], center = TRUE, scale. = TRUE)

# same scaling
print(all.equal(test$means, pca$center))
print(all.equal(test$sds, pca$scale))

# scores and loadings are the same or opposite
scores <- test$u \%*\% diag(test$d)
print(dim(scores))
print(dim(pca$x))
plot(as.numeric(scores), as.numeric(pca$x))
plot(as.numeric(test$v), as.numeric(pca$rotation))

# reconstruction
print(all.equal(tcrossprod(scores, test$v), scale(X[,]),
                check.attributes = FALSE))


# Using only half of the data for "training"
ind <- sort(sample(nrow(X), nrow(X)/2))

test2 <- big_SVD(X = X,
                 fun.scaling = big_scale(),
                 ind.train = ind,
                 block.size = 10)
str(test2)

pca2 <- prcomp(X[ind, ], center = TRUE, scale. = TRUE)

# same scaling
print(all.equal(test2$means, pca2$center))
print(all.equal(test2$sds, pca2$scale))

# scores and loadings are the same or opposite
# except for last eigenvalue which is equal to 0
# due to centering of columns
scores2 <- test2$u \%*\% diag(test2$d)
print(dim(scores2))
print(dim(pca2$x))
print(tail(pca2$sdev))
plot(as.numeric(scores2), as.numeric(pca2$x[, 1:ncol(scores2)]))
plot(as.numeric(test2$v), as.numeric(pca2$rotation[, 1:ncol(scores2)]))
}
\seealso{
\link[stats:prcomp]{prcomp}
}
